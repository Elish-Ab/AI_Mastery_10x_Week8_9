{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHqpCEh3tHfSX7q4CmWOgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elish-Ab/AI_Mastery_10x_Week8_9/blob/main/notebooks/Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xhj45WT96bff",
        "outputId": "959f4bc1-eb24-4364-8eb2-0dfd6005586f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.17.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.35)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.0->mlflow)\n",
            "  Downloading databricks_sdk-0.35.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.35.0-py3-none-any.whl (568 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.6 alembic-1.13.3 databricks-sdk-0.35.0 docker-7.1.0 graphene-3.4 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.0 mlflow-skinny-2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import mlflow\n",
        "import mlflow.sklearn"
      ],
      "metadata": {
        "id": "pJBn2MhX6IF2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "fraud_data = pd.read_csv('Fraud_Data.csv')\n",
        "credit_data = pd.read_csv('creditcard.csv')\n"
      ],
      "metadata": {
        "id": "9xTZe2Tj9BAp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fraud_Data.csv\n",
        "# Convert 'purchase_time' to datetime\n",
        "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
        "\n",
        "# Convert 'purchase_time' to datetime\n",
        "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
        "\n",
        "# Extract useful time-based features\n",
        "fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
        "fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.weekday\n",
        "\n",
        "# Drop columns not needed for training\n",
        "X_fraud = fraud_data.drop(columns=['purchase_time', 'signup_time', 'class', 'user_id', 'device_id', 'ip_address'])\n",
        "\n",
        "# One-hot encode categorical columns (e.g., 'source', 'browser', 'sex')\n",
        "X_fraud = pd.get_dummies(X_fraud, columns=['source', 'browser', 'sex'], drop_first=True)\n",
        "\n",
        "# Separate target variable\n",
        "y_fraud = fraud_data['class']\n",
        "\n",
        "# Split data\n",
        "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.3, random_state=42)\n",
        "\n",
        "# creditcard.csv\n",
        "X_credit = credit_data.drop(columns=['Class'])\n",
        "y_credit = credit_data['Class']\n",
        "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "-5QdNYNn7KOh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{name} Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "X_dyfvBk-vR9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start MLflow experiment tracking\n",
        "mlflow.end_run()  # Ensure any previous run is closed\n",
        "mlflow.start_run()\n",
        "\n",
        "# Scaling data\n",
        "scaler = StandardScaler()\n",
        "X_train_fraud_scaled = scaler.fit_transform(X_train_fraud)\n",
        "X_test_fraud_scaled = scaler.transform(X_test_fraud)\n",
        "X_train_credit_scaled = scaler.fit_transform(X_train_credit)\n",
        "X_test_credit_scaled = scaler.transform(X_test_credit)"
      ],
      "metadata": {
        "id": "aqoN3bBN-129"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training and Evaluation"
      ],
      "metadata": {
        "id": "FU_lQ9yU_XTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kNrjGSp6C8i",
        "outputId": "0888a49c-1532-48bf-fabe-45a88a4d6f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (Fraud Data) Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.54      0.68     41117\n",
            "           1       0.10      0.50      0.17      4217\n",
            "\n",
            "    accuracy                           0.54     45334\n",
            "   macro avg       0.51      0.52      0.42     45334\n",
            "weighted avg       0.84      0.54      0.63     45334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:54:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (Credit Data) Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     85307\n",
            "           1       0.06      0.93      0.10       136\n",
            "\n",
            "    accuracy                           0.97     85443\n",
            "   macro avg       0.53      0.95      0.55     85443\n",
            "weighted avg       1.00      0.97      0.99     85443\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:54:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree (Fraud Data) Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94     41117\n",
            "           1       0.45      0.57      0.50      4217\n",
            "\n",
            "    accuracy                           0.89     45334\n",
            "   macro avg       0.70      0.75      0.72     45334\n",
            "weighted avg       0.91      0.89      0.90     45334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:54:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Fraud Data) Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98     41117\n",
            "           1       0.95      0.54      0.69      4217\n",
            "\n",
            "    accuracy                           0.95     45334\n",
            "   macro avg       0.95      0.77      0.83     45334\n",
            "weighted avg       0.95      0.95      0.95     45334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:54:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting (Fraud Data) Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     41117\n",
            "           1       1.00      0.00      0.00      4217\n",
            "\n",
            "    accuracy                           0.91     45334\n",
            "   macro avg       0.95      0.50      0.48     45334\n",
            "weighted avg       0.92      0.91      0.86     45334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:54:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.3329 - val_accuracy: 0.9076 - val_loss: 0.3078\n",
            "Epoch 2/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.3127 - val_accuracy: 0.9076 - val_loss: 0.3059\n",
            "Epoch 3/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.3077 - val_accuracy: 0.9076 - val_loss: 0.3050\n",
            "Epoch 4/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.3037 - val_accuracy: 0.9076 - val_loss: 0.3045\n",
            "Epoch 5/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.3083 - val_accuracy: 0.9076 - val_loss: 0.3048\n",
            "Epoch 6/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3085 - val_accuracy: 0.9076 - val_loss: 0.3019\n",
            "Epoch 7/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.3003 - val_accuracy: 0.9077 - val_loss: 0.3011\n",
            "Epoch 8/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.3051 - val_accuracy: 0.9076 - val_loss: 0.2999\n",
            "Epoch 9/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.3031 - val_accuracy: 0.9076 - val_loss: 0.3008\n",
            "Epoch 10/10\n",
            "\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3029 - val_accuracy: 0.9076 - val_loss: 0.2983\n",
            "\u001b[1m1417/1417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:56:12 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "2024/10/22 06:56:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        }
      ],
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_test, y_test, name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{name} Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Ensure previous MLflow run is ended\n",
        "mlflow.end_run()\n",
        "\n",
        "# Start the main MLflow run\n",
        "with mlflow.start_run() as parent_run:\n",
        "\n",
        "    # Logistic Regression (Fraud Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        logreg_fraud = LogisticRegression(class_weight='balanced')\n",
        "        logreg_fraud.fit(X_train_fraud_scaled, y_train_fraud)\n",
        "        evaluate_model(logreg_fraud, X_test_fraud_scaled, y_test_fraud, \"Logistic Regression (Fraud Data)\")\n",
        "        mlflow.log_param(\"Model\", \"Logistic Regression (Fraud Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Fraud_Data\", logreg_fraud.score(X_test_fraud_scaled, y_test_fraud))\n",
        "        mlflow.sklearn.log_model(logreg_fraud, \"logreg_fraud_model\")\n",
        "\n",
        "    # Logistic Regression (Credit Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        logreg_credit = LogisticRegression(class_weight='balanced')\n",
        "        logreg_credit.fit(X_train_credit_scaled, y_train_credit)\n",
        "        evaluate_model(logreg_credit, X_test_credit_scaled, y_test_credit, \"Logistic Regression (Credit Data)\")\n",
        "        mlflow.log_param(\"Model\", \"Logistic Regression (Credit Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Credit_Data\", logreg_credit.score(X_test_credit_scaled, y_test_credit))\n",
        "        mlflow.sklearn.log_model(logreg_credit, \"logreg_credit_model\")\n",
        "\n",
        "    # Decision Tree (Fraud Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        dtree_fraud = DecisionTreeClassifier(random_state=42)\n",
        "        dtree_fraud.fit(X_train_fraud_scaled, y_train_fraud)\n",
        "        evaluate_model(dtree_fraud, X_test_fraud_scaled, y_test_fraud, \"Decision Tree (Fraud Data)\")\n",
        "        mlflow.log_param(\"Model\", \"Decision Tree (Fraud Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Fraud_Data_DTree\", dtree_fraud.score(X_test_fraud_scaled, y_test_fraud))\n",
        "        mlflow.sklearn.log_model(dtree_fraud, \"dtree_fraud_model\")\n",
        "\n",
        "    # Random Forest (Fraud Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        rf_fraud = RandomForestClassifier(random_state=42)\n",
        "        rf_fraud.fit(X_train_fraud_scaled, y_train_fraud)\n",
        "        evaluate_model(rf_fraud, X_test_fraud_scaled, y_test_fraud, \"Random Forest (Fraud Data)\")\n",
        "        mlflow.log_param(\"Model\", \"Random Forest (Fraud Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Fraud_Data_RF\", rf_fraud.score(X_test_fraud_scaled, y_test_fraud))\n",
        "        mlflow.sklearn.log_model(rf_fraud, \"rf_fraud_model\")\n",
        "\n",
        "    # Gradient Boosting (Fraud Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        gb_fraud = GradientBoostingClassifier(random_state=42)\n",
        "        gb_fraud.fit(X_train_fraud_scaled, y_train_fraud)\n",
        "        evaluate_model(gb_fraud, X_test_fraud_scaled, y_test_fraud, \"Gradient Boosting (Fraud Data)\")\n",
        "        mlflow.log_param(\"Model\", \"Gradient Boosting (Fraud Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Fraud_Data_GB\", gb_fraud.score(X_test_fraud_scaled, y_test_fraud))\n",
        "        mlflow.sklearn.log_model(gb_fraud, \"gb_fraud_model\")\n",
        "\n",
        "    # Multi-Layer Perceptron (MLP) with TensorFlow (Fraud Data)\n",
        "    with mlflow.start_run(nested=True):\n",
        "        mlp_model = tf.keras.Sequential([\n",
        "            layers.Dense(64, activation='relu', input_shape=(X_train_fraud_scaled.shape[1],)),\n",
        "            layers.Dense(32, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        mlp_model.fit(X_train_fraud_scaled, y_train_fraud, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "        # Evaluate MLP model\n",
        "        mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test_fraud_scaled, y_test_fraud)\n",
        "        mlflow.log_param(\"Model\", \"MLP (Fraud Data)\")\n",
        "        mlflow.log_metric(\"Accuracy_Fraud_Data_MLP\", mlp_accuracy)\n",
        "\n",
        "        # Log the MLP model using mlflow.tensorflow\n",
        "        mlflow.tensorflow.log_model(mlp_model, \"mlp_fraud_model\")\n",
        "\n",
        "# End MLflow parent run\n",
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJhNUVXh7DTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}